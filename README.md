# ğŸ§  Reminisce AI - Memory Support Platform

**AI-powered reminiscence therapy and comprehensive health management platform for Alzheimer's patients and their caretakers.**

Built by Team ResQR | Powered by Microsoft Azure AI + Google Gemini

ğŸŒ **Live Demo:** [https://reminisce-agent.vercel.app/](https://reminisce-agent.vercel.app/)

ğŸ“¡ **Backend API:** [https://reminisce-agent.onrender.com](https://reminisce-agent.onrender.com)

---

## âœ¨ Key Features

### ğŸ¯ Core Functionality

- **ğŸ–¼ï¸ Memory Hub** - Interactive photo memory system with AI-generated personalized questions
- **ğŸ¤ Voice Assistant** - Hands-free navigation with voice commands
- **ğŸ“… Daily Routines** - Track and manage daily tasks and activities
- **ğŸš¨ Emergency SOS** - One-tap emergency alert system for caretakers
- **ğŸ‘¥ Caretaker Dashboard** - Comprehensive monitoring and management tools

### ğŸ¤– AI-Powered Features

1. **Image Analysis** (Azure Computer Vision)
   - Automatic photo caption generation
   - Object and scene detection
   - Tag extraction for memory context

2. **Memory Questions** (Google Gemini 2.0 Flash)
   - Generates 5 personalized questions per photo
   - Rotates questions every 12 hours
   - Contextual and emotionally engaging prompts

3. **Text-to-Speech** (Azure Speech Service)
   - Natural voice playback of memory questions
   - Accessible audio interface
   - Warm, friendly voice output

4. **Voice Commands** (Web Speech API)
   - "Show me my memories" - Opens Memory Hub
   - "Help!" / "Call caretaker" - Triggers emergency alert
   - "What are my tasks?" - Shows daily routines
   - "What time is it?" - Displays current time
   - "Play question" - Reads memory question aloud

---

## ğŸ› ï¸ Tech Stack

**Frontend:**
- React 18 + TypeScript
- TailwindCSS (Custom high-contrast theme)
- Framer Motion (Animations)
- React Query (State management)
- Vite (Build tool)

**Backend:**
- Express.js + Node.js
- MongoDB (Database)
- Passport.js (Authentication)

**AI Services:**
- Microsoft Azure Computer Vision API
- Microsoft Azure Speech Service
- Google Gemini 2.0 Flash Experimental
- Web Speech API (Browser-based voice recognition)

---

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** 18.0+
- **MongoDB** 6.0+
- **Azure Account** (for Vision + Speech APIs)
- **Google AI Studio Account** (for Gemini API)

### 1. Clone & Install

```bash
git clone <repository-url>
cd Reminisce-AI
npm install
```

### 2. Environment Configuration

Create a `.env` file in the root directory:

```env
# Database (Use MongoDB Atlas for production)
DATABASE_URL=mongodb+srv://username:password@cluster.mongodb.net/reminisce_ai?retryWrites=true&w=majority
DATABASE_NAME=reminisce_ai

# Session Security
SESSION_SECRET=your-secure-random-secret-at-least-32-characters-long

# Microsoft Azure Computer Vision (Image Analysis)
AZURE_COMPUTER_VISION_ENDPOINT=https://your-endpoint.cognitiveservices.azure.com/
AZURE_COMPUTER_VISION_KEY=your-computer-vision-api-key

# Microsoft Azure Speech Service (Text-to-Speech)
AZURE_SPEECH_ENDPOINT=https://your-region.api.cognitive.microsoft.com/
AZURE_SPEECH_KEY=your-speech-api-key
AZURE_SPEECH_REGION=your-azure-region

# Google Gemini AI (Question Generation)
GEMINI_API_KEY=your-gemini-api-key-from-ai-studio
```

### 3. Database Setup

**Local Development:**
```bash
# Windows
net start MongoDB

# Linux/Mac
sudo systemctl start mongod
```

**Production (MongoDB Atlas):**
1. Create account at [mongodb.com/cloud/atlas](https://www.mongodb.com/cloud/atlas)
2. Create a new cluster
3. Get connection string and add to `.env`
4. Collections are created automatically on first run

### 4. Run the Application

**Development Mode:**
```bash
npm run dev
```

**Production Build:**
```bash
npm run build
npm start
```

The application will be available at **http://localhost:5000**

---

## ğŸ“ Project Structure

```
Reminisce-AI/
â”œâ”€â”€ client/                 # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/ui/  # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ hooks/          # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ lib/            # Utility functions
â”‚   â”‚   â”œâ”€â”€ pages/          # Main page components
â”‚   â”‚   â”‚   â”œâ”€â”€ PatientDashboard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ CaretakerDashboard.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Auth.tsx
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â””â”€â”€ index.html
â”‚
â”œâ”€â”€ server/                 # Express backend
â”‚   â”œâ”€â”€ auth.ts            # Authentication logic
â”‚   â”œâ”€â”€ azure_services.ts  # Azure API integration
â”‚   â”œâ”€â”€ db.ts              # MongoDB connection
â”‚   â”œâ”€â”€ routes.ts          # API endpoints
â”‚   â”œâ”€â”€ storage.ts         # File storage
â”‚   â””â”€â”€ index.ts           # Server entry point
â”‚
â”œâ”€â”€ shared/                 # Shared types & schemas
â”‚   â”œâ”€â”€ routes.ts          # Route definitions
â”‚   â””â”€â”€ schema.ts          # Database schemas
â”‚
â”œâ”€â”€ script/                 # Build scripts
â”‚   â””â”€â”€ build.ts
â”‚
â”œâ”€â”€ package.json
â”œâ”€â”€ vite.config.ts
â”œâ”€â”€ tailwind.config.ts
â”œâ”€â”€ tsconfig.json
â””â”€â”€ .env
```

---

## ğŸ¨ UI Features

### Patient Dashboard
- **Memory Hub Modal** - Fullscreen photo viewer with carousel navigation
- **Animated Transitions** - Smooth Framer Motion animations throughout
- **Voice Assistant Overlay** - Real-time voice command processing
- **Responsive Design** - Mobile-first, works on all screen sizes
- **Accessibility** - High contrast colors, large touch targets, keyboard navigation

### Caretaker Dashboard
- **Batch Image Upload** - Upload multiple memories at once
- **Patient Management** - Monitor patient activity and health
- **Emergency Alerts** - Instant SOS notifications
- **Memory Management** - Add, edit, and organize patient memories

---

## ğŸ” Security

- **Session-based authentication** with secure HTTP-only cookies
- **Password hashing** using crypto.scrypt with random salts
- **Environment variable protection** for API keys
- **CORS configuration** for cross-origin security
- **MongoDB injection prevention** with Mongoose

---

## ğŸš€ API Endpoints

### Authentication
- `POST /api/register` - Create new user account
- `POST /api/login` - User authentication
- `POST /api/logout` - Session termination
- `GET /api/user` - Get current user info

### Memories
- `GET /api/memories` - Fetch patient memories
- `POST /api/memories` - Upload new memory with image
- `POST /api/text-to-speech` - Generate audio from text

### Routines
- `GET /api/routines` - Get patient routines
- `POST /api/routines` - Create new routine
- `PATCH /api/routines/:id` - Update routine status

### Emergency
- `POST /api/emergency` - Trigger SOS alert
- `GET /api/emergency-list` - Get emergency history

---

## ğŸ¯ Voice Commands

| Command | Action |
|---------|--------|
| "Show me my memories" | Opens Memory Hub modal |
| "Help!" / "SOS" | Triggers emergency alert |
| "Call caretaker" | Sends emergency notification |
| "What are my tasks?" | Scrolls to routines section |
| "What time is it?" | Displays current time |
| "Play question" | Plays memory question audio |
| "Close" / "Cancel" | Closes voice assistant |

---

## ï¿½ Deployment

### Current Deployment Stack

- **Frontend:** Vercel ([reminisce-agent.vercel.app](https://reminisce-agent.vercel.app/))
- **Backend:** Render ([reminisce-agent.onrender.com](https://reminisce-agent.onrender.com))
- **Database:** MongoDB Atlas (Cloud)

### Deploy Your Own

**Frontend (Vercel):**
1. Push code to GitHub
2. Import project at [vercel.com](https://vercel.com)
3. Set Framework: Vite
4. Set Output Directory: `dist/public`
5. Add environment variable: `VITE_API_URL=your-backend-url`

**Backend (Render):**
1. Create Web Service at [render.com](https://render.com)
2. Connect GitHub repository
3. Use `render.yaml` for automatic configuration
4. Add all environment variables from `.env`

---

## ï¿½ğŸ”§ Development

### Available Scripts

```bash
npm run dev          # Start development server (Vite + Express)
npm run build        # Production build (TypeScript â†’ dist/)
npm start            # Run production server
npm run check        # TypeScript type checking
```

### Environment Modes

- **Development** - Hot module replacement, detailed errors
- **Production** - Optimized bundle, minified assets

---

## ğŸ“ Database Schema

### User Collection
```typescript
{
  id: number,
  username: string,
  password: string (hashed),
  role: "patient" | "caretaker",
  caretakerId?: number
}
```

### Memory Collection
```typescript
{
  id: number,
  patientId: number,
  imageUrl: string,
  description: string,
  aiQuestions: string[],  // 5 AI-generated questions
  lastQuestionIndex: number,
  createdAt: Date
}
```

### Routine Collection
```typescript
{
  id: number,
  patientId: number,
  task: string,
  time: string,
  completed: boolean
}
```

---

## ğŸŒ Browser Compatibility

- **Chrome/Edge** âœ… (Full support including voice recognition)
- **Firefox** âš ï¸ (No voice recognition support)
- **Safari** âš ï¸ (Limited voice recognition support)

*Voice assistant requires browser support for Web Speech API*

---

## ğŸ¤ Contributing

This project was built for hackathon submission. Future enhancements:
- [ ] Mobile app (React Native)
- [ ] Multi-language support
- [ ] Advanced analytics dashboard
- [ ] Video memory support
- [ ] Integration with wearable devices

---

## ğŸ“œ License

MIT License - feel free to use and modify for your projects!

---

## ğŸ‘¥ Team ResQR

Built with â¤ï¸ by Team ResQR

**Technologies:** Microsoft Azure AI, Google Gemini, React, TypeScript, MongoDB, Express.js

---

## ğŸ™ Acknowledgments

- **Microsoft Azure** for Computer Vision and Speech Services
- **Google** for Gemini AI API
- **Vercel** for shadcn/ui components
- **Framer** for Motion animations library

---

*For support or questions, please open an issue on GitHub.*

